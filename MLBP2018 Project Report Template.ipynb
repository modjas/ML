{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Basic Principles 2018 - Data Analysis Project Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All the text in italics is instructions for filling the template - remove when writing the project report!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Title* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Title should be concise and informative, describes the approach to solve the problem. Some good titles from previous years:*\n",
    "\n",
    "*- Comparing extreme learning machines and naive bayes’ classifier in spam detection*\n",
    "\n",
    "*- Using linear discriminant analysis in spam detection*\n",
    "\n",
    "*Some not-so-good titles:*\n",
    "\n",
    "*- Bayesian spam filtering with extras*\n",
    "\n",
    "*- Two-component classifier for spam detection*\n",
    "\n",
    "*- CS-E3210 Term Project, final report*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Precise summary of the whole report, previews the contents and results. Must be a single paragraph between 100 and 200 words.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Background, problem statement, motivation, many references, description of\n",
    "contents. Introduces the reader to the topic and the broad context within which your\n",
    "research/project fits*\n",
    "\n",
    "*- What do you hope to learn from the project?*\n",
    "*- What question is being addressed?*\n",
    "*- Why is this task important? (motivation)*\n",
    "\n",
    "*Keep it short (half to 1 page).*\n",
    "\n",
    ".-.-.-.-.-.-.-.-\n",
    "\n",
    "Assigning a genre to a song is a task at which even humans might have different opinions as to what is the correct genre. Thus we can expect that teaching a computer to correctly predict a genre for a given song is no easy feat.\n",
    "\n",
    "Our task is to teach a computer to assign a genre to a song, based on data extracted from the song. The two most important outcomes from this project are\n",
    "\n",
    "1. How well can a computer predict the genre of a song based on simple Machine Learning algorithms\n",
    "2. Can we generalize the problem to gain an understanding of how well we can classify other real-world \n",
    "\n",
    "We have two datasets consisting of song features, with one of the datasets being labeled to specific genres. Depending on the bitrate and audio format a single song can be several tens of megabytes, with normal listening bitrate for an mp3-file requiring at least a few megabytes. This means that using all bits in the song would result in a huge dataset impractical for our purposes.\n",
    "\n",
    "Luckily our dataset has the songs preprocessed into vectors of 264 features. The features contain information about the rhytm pattern, chroma and Mel Frequency Cepstral Coefficients (MFFC). Further understanding of the vectors is not needed for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Briefly describe data (class distribution, dimensionality) and how will it affect\n",
    "classification. Visualize the data. Don’t focus too much on the meaning of the features,\n",
    "unless you want to.*\n",
    "\n",
    "*- Include histograms showing class distribution.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and cleanup\n",
    "train_data = pd.read_csv(\"train_data.csv\", header=None)\n",
    "test_data = pd.read_csv(\"test_data.csv\", header=None)\n",
    "train_labels = pd.read_csv(\"train_labels.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon closer inspection of the data we see that many columns seem to have bad data. \n",
    "For example column with index 204 has mostly ones and column with index 216 is almost all 1E+06.\n",
    "In the cell below we remove the coumns having bad data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cleaned = train_data.copy()\n",
    "train_data_cleaned = train_data_cleaned.drop(train_data_cleaned.iloc[:, 204:219], axis=1)\n",
    "\n",
    "test_data_cleaned = test_data.copy()\n",
    "test_data_cleaned = test_data_cleaned.drop(test_data_cleaned.iloc[:, 204:219], axis=1)\n",
    "\n",
    "#TODO Remove column 143\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4363, 264) (6544, 264) (4363, 1)\n"
     ]
    }
   ],
   "source": [
    "#Analysddis of the input data: MATTE\n",
    "print(train_data.shape, test_data.shape, train_labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Histogram of class distribution\n",
    "\n",
    "#class_labels = ['Pop_Rock', 'Electronic', 'Rap', 'Jazz', 'Latin', 'RnB', 'International', 'Country', 'Reggae', 'Blues']\n",
    "\n",
    "plt.hist(train_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4363, 20)\n"
     ]
    }
   ],
   "source": [
    "#Analysis of the input data: MATTI\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#TODO: divide data training data and labels into two halves - one for training, the other for validation\n",
    "#TODO: Counteract imbalance in data set\n",
    "\n",
    "def create_reduced_data(data):\n",
    "    assert data.shape[1] == 264\n",
    "    N=data.shape[0]\n",
    "    reduced_data=np.zeros((N,96))\n",
    "    for i in range(0,N):\n",
    "        #1: Collect mean and variance of all 24 rhythm bands. Each band consists of 7 statistics\n",
    "        for j in range(0,24):\n",
    "            mean=data[i,j*7]\n",
    "            variance=data[i,j*7+2]\n",
    "            reduced_data[i,2*j]=mean\n",
    "            reduced_data[i,2*j+1]=variance\n",
    "        #2: Collect mean and standard deviation of all 12 chroma bands. Each band consists of 4 statistics\n",
    "        for j in range(0,12):\n",
    "            mean=data[i,168+j*4]\n",
    "            std_dev=data[i,168+j*4+1]\n",
    "            reduced_data[i,48+2*j]=mean\n",
    "            reduced_data[i,48+2*j+1]=std_dev\n",
    "        #3: Collect mean and standard deviation of all 12 MFCC bands. Each band consists of 4 statistics\n",
    "        for j in range(0,12):\n",
    "            mean=data[i,216+j*4]\n",
    "            std_dev=data[i,216+j*4+1]\n",
    "            reduced_data[i,72+2*j]=mean\n",
    "            reduced_data[i,72+2*j+1]=std_dev\n",
    "    return reduced_data\n",
    "\n",
    "traindata_mat = train_data.as_matrix() # convert the data frame to numpy matrix\n",
    "testdata_mat = test_data.as_matrix() # convert the data frame to numpy matrix\n",
    "reduced_traindata=create_reduced_data(traindata_mat)\n",
    "reduced_testdata=create_reduced_data(testdata_mat)\n",
    "\n",
    "cov=np.cov(np.transpose(traindata_mat))\n",
    "eigenValues, eigenVectors = np.linalg.eig(cov)\n",
    "#idx = eigenValues.argsort()[::-1]\n",
    "\n",
    "#test principal component analysis of data\n",
    "pca=PCA(n_components = 20)\n",
    "pca.fit(traindata_mat)\n",
    "traindata_PCA=pca.transform(traindata_mat)\n",
    "testdata_PCA=pca.transform(testdata_mat)\n",
    "print(traindata_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eigenvalues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d2f36fd8739d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number of eigenvalue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eigenvalue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First 20 eigenvalues of the covariance matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eigenvalues' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0ec1d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.plot(eigenvalues[0:20])\n",
    "plt.xlabel('number of eigenvalue')\n",
    "plt.ylabel('eigenvalue')\n",
    "plt.title(\"First 20 eigenvalues of the covariance matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods and experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*- Explain your whole approach (you can include a block diagram showing the steps in your process).* \n",
    "\n",
    "*- What methods/algorithms, why were the methods chosen. *\n",
    "\n",
    "*- What evaluation methodology (cross CV, etc.).*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression score:  0.33223979956167965\n",
      "Deep learning score:  0.49919779967911987\n",
      "Bayesian Ridge Regression score:  0.2488757358386392\n",
      "Random Forest score:  0.8542287416914967\n"
     ]
    }
   ],
   "source": [
    "# Trials with ML algorithms\n",
    "\n",
    "#TODO\n",
    "#Polynomial regression\n",
    "\n",
    "#Mattes algoritmer\n",
    "#Try 1, LinearRegression\n",
    "classifier_1 = linear_model.LinearRegression().fit(train_data_cleaned, train_labels)\n",
    "score1 = classifier_1.score(train_data_cleaned, train_labels)\n",
    "classifier_1.predict(test_data_cleaned)\n",
    "\n",
    "#Try 2, SVM\n",
    "#classifier_2 = SVC(gamma='auto')\n",
    "#classifier_2.fit(train_data, train_labels.values.ravel())\n",
    "#classifier_2.score(train_data, train_labels.values.ravel())\n",
    "\n",
    "#Try 3, Deep learning\n",
    "classifier_3 = MLPClassifier(solver='lbfgs', alpha=1e-2, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "classifier_3.fit(train_data_cleaned, train_labels.values.ravel())\n",
    "score3 = classifier_3.score(train_data_cleaned, train_labels.values.ravel())\n",
    "\n",
    "#Try 4, Bayesian Ridge regression\n",
    "classifier_4 = linear_model.BayesianRidge().fit(train_data_cleaned, train_labels.values.ravel())\n",
    "score4 = classifier_4.score(train_data_cleaned, train_labels.values.ravel())\n",
    "\n",
    "#Try 5, Random Forest\n",
    "classifier_5 = RandomForestClassifier(n_estimators=100, max_depth = 10).fit(train_data_cleaned, train_labels.values.ravel())\n",
    "score5 = classifier_5.score(train_data_cleaned, train_labels.values.ravel())\n",
    "classifier_5_output = classifier_5.predict(test_data_cleaned)\n",
    "classifier_5_output_logloss = classifier_5.predict_proba(test_data_cleaned)\n",
    "\n",
    "\n",
    "#Output\n",
    "print(\"Linear regression score: \", score1)\n",
    "print(\"Deep learning score: \", score3)\n",
    "print(\"Bayesian Ridge Regression score: \", score4)\n",
    "print(\"Random Forest score: \", score5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score with PCA compression, boom:  0.7779051111620444\n"
     ]
    }
   ],
   "source": [
    "#Mattis algoritmer\n",
    "#Try the same as above, but for the reduced data\n",
    "\n",
    "classifier_5_reduced = RandomForestClassifier(n_estimators=10, max_depth = 10).fit(traindata_PCA, train_labels.values.ravel())\n",
    "score5_reduced = classifier_5_reduced.score(traindata_PCA, train_labels.values.ravel())\n",
    "classifier_5_reduced_output = classifier_5_reduced.predict(testdata_PCA)\n",
    "\n",
    "\n",
    "#Output\n",
    "print(\"Random Forest score with PCA compression, boom: \", score5_reduced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Summarize the results of the experiments without discussing their implications.*\n",
    "\n",
    "*- Include both performance measures (accuracy and LogLoss).*\n",
    "\n",
    "*- How does it perform on kaggle compared to the train data.*\n",
    "\n",
    "*- Include a confusion matrix.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix ...\n",
    "\n",
    "#Output for Accuracy competition\n",
    "output_csv = pd.DataFrame({'Sample_label': classifier_5_output})\n",
    "output_csv.index += 1\n",
    "output_csv.index.names = ['Sample_id']\n",
    "\n",
    "#Output for Logloss competition\n",
    "output_csv2 = pd.DataFrame(classifier_5_output_logloss, columns=['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5','Class_6','Class_7','Class_8','Class_9','Class_10',])\n",
    "output_csv2.index += 1\n",
    "output_csv2.index.names = ['Sample_id']\n",
    "\n",
    "#output_csv.rename({1: \"Sample_id\", 2: \"Sample_label\"}, index=)\n",
    "output_csv.to_csv('upload_to_kaggle_accuracy.csv')\n",
    "output_csv2.to_csv('upload_to_kaggle_logloss.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion/Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpret and explain your results *\n",
    "\n",
    "*- Discuss the relevance of the performance measures (accuracy and LogLoss) for\n",
    "imbalanced multiclass datasets. *\n",
    "\n",
    "*- How the results relate to the literature. *\n",
    "\n",
    "*- Suggestions for future research/improvement. *\n",
    "\n",
    "*- Did the study answer your questions? *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*List of all the references cited in the document*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "*Any additional material needed to complete the report can be included here. For example, if you want to keep  additional source code, additional images or plots, mathematical derivations, etc. The content should be relevant to the report and should help explain or visualize something mentioned earlier. **You can remove the whole Appendix section if there is no need for it.** *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
